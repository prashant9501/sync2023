{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8204fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps for Model Building\n",
    "# 0. Convert your Business problem into a Data Problem\n",
    "# 1. Load the dataset\n",
    "# 2. Exploratory Data Analysis:\n",
    "# 3. Bare minimum data cleaning (e.g. missing value imputation) & \n",
    "# preprocessing (e.g. Encoding the cat. variables)\n",
    "\n",
    "# 4. Create Baseline models\n",
    "\n",
    "# 5. Data Polishing/Refinement: e.g. outlier treatment, scaling the num. features,\n",
    "# Feature engineering, feature selection, feature transformation, etc.\n",
    "\n",
    "# ===> Data is FInalized!!\n",
    "# 6. Compare and Select the best model(s) for \"tuning\" \n",
    "\n",
    "# 7. Hyper-parameter tuning / Model Refinement\n",
    "\n",
    "# 8. Re-train you final model on the entire data, one last time!\n",
    "\n",
    "# 9. Save the model (pickelize)\n",
    "\n",
    "# 10. Share/Deploy the model\n",
    "\n",
    "# y = f(X)\n",
    "\n",
    "# Model = Algo(Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44aba459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle(\"churn_prediction_v3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a99ac14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'occupation', 'city', 'customer_nw_category', 'branch_code',\n",
       "       'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = df.dtypes[df.dtypes == 'category'].index  # identifying the categorical variable\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7119f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : 2\n",
      "occupation : 5\n",
      "city : 1288\n",
      "customer_nw_category : 3\n",
      "branch_code : 2806\n",
      "churn : 2\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:  # list the number of unique values in these cat. columns\n",
    "    print(col, \":\", df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ffa1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"city\", axis=1, inplace=True)          # Dropping the columns, as it has just too many unique values\n",
    "df.drop( 'branch_code', axis=1, inplace=True)  # Dropping the columns, as it has just too many unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f28a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map({'Male':0, 'Female':1})  # Label Encoding the gender col. This can also be One-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b7b5aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retired</th>\n",
       "      <th>salaried</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>student</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15924</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15925</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15926</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15927</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15928</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15929 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       retired  salaried  self_employed  student\n",
       "0            0         0              1        0\n",
       "1            0         0              1        0\n",
       "2            0         1              0        0\n",
       "3            0         0              1        0\n",
       "4            0         0              1        0\n",
       "...        ...       ...            ...      ...\n",
       "15924        0         1              0        0\n",
       "15925        0         0              1        0\n",
       "15926        0         1              0        0\n",
       "15927        0         0              1        0\n",
       "15928        0         0              1        0\n",
       "\n",
       "[15929 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['occupation'], drop_first=True)   # OHE the occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91fa888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols = ['occupation', 'customer_nw_category'] # Selecting out the columns for OHE    #  'city', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36797b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(df, columns=nominal_cols) # One-Hot encoding the Nominal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95adca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15929 entries, 0 to 15928\n",
      "Data columns (total 23 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   vintage                         15929 non-null  int64   \n",
      " 1   age                             15929 non-null  int64   \n",
      " 2   gender                          15929 non-null  category\n",
      " 3   dependents                      15929 non-null  int64   \n",
      " 4   current_balance                 15929 non-null  float64 \n",
      " 5   previous_month_end_balance      15929 non-null  float64 \n",
      " 6   average_monthly_balance_prevQ   15929 non-null  float64 \n",
      " 7   average_monthly_balance_prevQ2  15929 non-null  float64 \n",
      " 8   current_month_credit            15929 non-null  float64 \n",
      " 9   previous_month_credit           15929 non-null  float64 \n",
      " 10  current_month_debit             15929 non-null  float64 \n",
      " 11  previous_month_debit            15929 non-null  float64 \n",
      " 12  current_month_balance           15929 non-null  float64 \n",
      " 13  previous_month_balance          15929 non-null  float64 \n",
      " 14  churn                           15929 non-null  category\n",
      " 15  occupation_company              15929 non-null  uint8   \n",
      " 16  occupation_retired              15929 non-null  uint8   \n",
      " 17  occupation_salaried             15929 non-null  uint8   \n",
      " 18  occupation_self_employed        15929 non-null  uint8   \n",
      " 19  occupation_student              15929 non-null  uint8   \n",
      " 20  customer_nw_category_1          15929 non-null  uint8   \n",
      " 21  customer_nw_category_2          15929 non-null  uint8   \n",
      " 22  customer_nw_category_3          15929 non-null  uint8   \n",
      "dtypes: category(2), float64(10), int64(3), uint8(8)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "646cb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new[df_new.dtypes[df_new.dtypes == \"bool\"].index] = df_new[df_new.dtypes[df_new.dtypes == \"bool\"].index].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03073c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_pickle(\"cleaned_churn_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c8f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4558d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d26946a",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "### What are Ensemble Models?\n",
    "\n",
    "Ensemble models in machine learning combine the decisions from multiple models to improve the overall performance. This approach is based on the premise that a group of weak learners can come together to form a strong learner. The individual models in an ensemble are known as base learners.\n",
    "\n",
    "### Why Do We Need Them?\n",
    "\n",
    "1. **Improved Accuracy**: Ensembles often provide better predictions and achieve higher accuracy than individual models. They are particularly effective in reducing variance and bias.\n",
    "\n",
    "2. **Reduced Overfitting**: By averaging out biases and capturing more general patterns, ensembles can reduce the risk of overfitting compared to a single complex model.\n",
    "\n",
    "3. **Increased Robustness**: Ensembles are less sensitive to the quirks of individual models and can provide more stable and reliable predictions.\n",
    "\n",
    "4. **Handling Complexity**: They can model complex relationships in data by combining simpler models, which might not be possible with a single model.\n",
    "\n",
    "### Different Techniques of Ensemble Models\n",
    "\n",
    "1. **Bagging (Bootstrap Aggregation)**:\n",
    "   - Combines predictions from multiple models trained on different random subsets of the training dataset.\n",
    "   - Example: Random Forest.\n",
    "\n",
    "2. **Boosting**:\n",
    "   - Sequentially trains models, where each model learns from the errors of its predecessor, emphasizing the instances that previous models misclassified.\n",
    "   - Example: XGBoost, LightGBM, CatBoost.\n",
    "\n",
    "3. **Stacking (Stacked Generalization)**:\n",
    "   - Trains multiple models on the same dataset and then trains a meta-model to combine their predictions.\n",
    "   - Example: Stacked ensemble of different algorithms like decision trees, SVMs, and neural networks.\n",
    "\n",
    "4. **Voting**:\n",
    "   - Simplest form of ensembling, combining predictions from multiple models. It can be majority voting (classification) or averaging/weighted averaging (regression).\n",
    "\n",
    "5. **Blending**:\n",
    "   - Similar to stacking but uses a validation set to train the meta-model instead of out-of-fold predictions.\n",
    "\n",
    "The choice of the right ensemble technique depends on the specific problem, the nature of the data, and the desired balance between bias and variance.\n",
    "\n",
    "### Problems Solved by Boosting vs Bagging Algorithms\n",
    "\n",
    "1. **Boosting**:\n",
    "   - **Problem Addressed**: Primarily reduces bias and builds strong predictive models. It sequentially focuses on difficult-to-classify instances, improving the model's performance on these cases.\n",
    "   - **Example**: AdaBoost, Gradient Boosting, XGBoost.\n",
    "   - **Use Cases**: Works well with weak base learners and in scenarios where bias reduction is crucial.\n",
    "\n",
    "2. **Bagging**:\n",
    "   - **Problem Addressed**: Aims to reduce variance and prevent overfitting. It involves training base learners on different subsets of the original dataset and then averaging their predictions.\n",
    "   - **Example**: Random Forest.\n",
    "   - **Use Cases**: Effective in high-variance scenarios and when the base learners are complex models like decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485696df",
   "metadata": {},
   "source": [
    "### Advantages of Ensemble Models:\n",
    "\n",
    "1. **Improved Accuracy**: Combining multiple models often leads to better predictions and higher accuracy than individual models, especially when the models complement each other's strengths.\n",
    "\n",
    "2. **Reduced Overfitting**: Ensemble methods, particularly those involving bagging or averaging approaches (like Random Forest), can reduce the risk of overfitting, as they average out biases and are less sensitive to noise in the training data.\n",
    "\n",
    "3. **Handling Non-Linearity**: Ensembles can capture complex, non-linear relationships in the data that might be missed by individual models.\n",
    "\n",
    "4. **Increased Robustness**: Ensemble methods are generally more robust and less sensitive to errors in individual models. This robustness comes from the aggregation of diverse predictions.\n",
    "\n",
    "5. **Model Diversity**: Ensembles can combine different types of models, leading to a diversity that can capture a wide range of patterns in the data.\n",
    "\n",
    "6. **Improved Performance on Imbalanced Datasets**: Techniques like boosting can focus on the harder-to-classify examples, thereby improving performance on imbalanced datasets.\n",
    "\n",
    "### Disadvantages of using Ensemble Models:\n",
    "\n",
    "1. **Increased Complexity**: Ensemble models are typically more complex to understand, implement, and interpret than individual models.\n",
    "\n",
    "2. **Higher Computational Cost**: They generally require more computational resources and time to train, especially if the ensemble size is large.\n",
    "\n",
    "3. **Risk of Overfitting with Boosting**: Although ensembles like Random Forests reduce the risk of overfitting, boosting methods (e.g., AdaBoost, Gradient Boosting) can overfit the training data if not carefully tuned.\n",
    "\n",
    "4. **Model Interpretability**: As the complexity of the model increases with ensembling, it becomes more challenging to interpret the model and understand the reasoning behind specific predictions.\n",
    "\n",
    "5. **Tuning Difficulty**: Ensemble methods introduce additional hyperparameters (like the number of models in the ensemble), which can make the process of model tuning more complex.\n",
    "\n",
    "6. **Dependency on Base Models**: The performance of an ensemble is limited by the performance of its base models. If the base models are too weak or too correlated, the ensemble's performance may not be optimal.\n",
    "\n",
    "Hence, while ensemble models can provide significant improvements in prediction accuracy and robustness, they come with increased complexity, computational costs, and potential challenges in interpretation and tuning. The choice to use ensemble models should be guided by the trade-off between these factors and the specific requirements of the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d58c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95103bac",
   "metadata": {},
   "source": [
    "# Comparing Gradient Boosting & AdaBoost\n",
    "\n",
    "| Feature/Aspect             | Gradient Boosting                                        | AdaBoost                                                   |\n",
    "|----------------------------|----------------------------------------------------------|------------------------------------------------------------|\n",
    "| **Basic Concept**          | Builds an additive model in a forward stage-wise fashion, optimizing arbitrary differentiable loss functions. | Boosts the performance of decision trees on binary classification problems by focusing on misclassified instances in training. |\n",
    "| **Algorithm Type**         | General approach that can be used with any differentiable loss function. | Initially designed for classification problems, but can be extended to regression. |\n",
    "| **Weight Update Mechanism**| Adjusts the model by fitting the new predictor to the residual errors made by the previous predictor. | Adjusts the weights of incorrectly classified instances, making them more likely to be correctly classified in the next round. |\n",
    "| **Learning Rate**          | Uses a learning rate to shrink the contribution of each tree to prevent overfitting. | Does not inherently use a learning rate; instead, it adjusts weights after each iteration based on error. |\n",
    "| **Base Learner**           | Typically decision trees (can be shallow, like stumps, or deeper). | Often uses decision stumps (single-level decision trees) as the weak learners. |\n",
    "| **Loss Function Adaptation**| Can optimize different loss functions (squared error, logistic loss, etc.). | Focuses on exponential loss function. |\n",
    "| **Flexibility**            | More flexible, as it works with various loss functions and allows for more complex base learners. | Less flexible with respect to the choice of loss function and base learner. |\n",
    "| **Robustness to Overfitting**| Has mechanisms to prevent overfitting (like using subsamples of data, smaller learning rates, or limiting the number of trees). | Can overfit if the number of weak learners is too high, especially in the presence of noise. |\n",
    "| **Speed and Scalability**  | Can be slower and more computationally intensive due to deeper trees and sequential building of models. | Generally faster and less computationally expensive as it often uses simpler base models. |\n",
    "| **Use Cases**              | Broad range of applications in regression, classification, ranking, etc. | Mainly used in classification problems but can be adapted for regression. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135383c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb38cb8",
   "metadata": {},
   "source": [
    "# Comparing XGBoost, LightGBM, and CatBoost:\n",
    "\n",
    "\n",
    "| Feature                   | XGBoost                          | LightGBM                         | CatBoost                         |\n",
    "|---------------------------|----------------------------------|----------------------------------|----------------------------------|\n",
    "| **Full Name**             | eXtreme Gradient Boosting        | Light Gradient Boosting Machine  | Categorical Boosting             |\n",
    "| **Developer**             | Developed by Tianqi Chen         | Microsoft                        | Yandex                           |\n",
    "| **Release Year**          | 2016                             | 2017                             | 2017                             |\n",
    "| **Algorithm**             | Gradient boosting decision trees | Gradient boosting decision trees | Gradient boosting decision trees |\n",
    "| **Key Features**          | - Regularization capabilities<br>- Robust handling of missing values<br>- Tree pruning based on depth-first approach | - Faster training on large datasets due to histogram-based splits<br>- Leaf-wise tree growth which can result in better performance<br>- Lower memory usage | - Specialized handling of categorical features without need for explicit pre-processing<br>- Robust to overfitting with small datasets<br>- Advanced handling of categorical features |\n",
    "| **Handling Categorical Features** | Requires pre-processing (like one-hot encoding) | Requires pre-processing (like one-hot encoding) | Directly handles categorical features with no need for explicit pre-processing |\n",
    "| **Speed and Scalability** | Slower than LightGBM but very efficient on small to medium datasets | Very fast, especially on large datasets due to histogram-based algorithms | Competitively fast, efficient in memory usage, especially with categorical data |\n",
    "| **Ease of Use**           | Easy to use with extensive documentation and community support | Slightly more complex due to additional parameters for tuning | User-friendly with less need for hyper-parameter tuning |\n",
    "| **Model Interpretability**| Good with various tools available for visualization | Good with tools for visualization but might be less interpretable due to complex leaf-wise growth | Good with detailed explanations for model predictions |\n",
    "| **Regularization**        | Supports both L1 (Lasso regression) and L2 (Ridge regression) regularization to prevent overfitting | Limited regularization options compared to XGBoost | Provides a form of regularization to prevent overfitting |\n",
    "| **Community and Support** | Very popular with a large community, extensive documentation | Growing popularity, good community support | Gaining popularity, especially in the European market, with good documentation |\n",
    "| **Use Case Scenarios**    | - Small to medium data sets<br>- Scenarios requiring fine-tuned models | - Large datasets and scenarios where training speed is crucial<br>- Situations where memory efficiency is important | - Datasets with a high proportion of categorical features<br>- When model interpretability is important<br>- Scenarios with smaller datasets where overfitting might be a concern |\n",
    "\n",
    "Each of these frameworks has its strengths and is better suited to certain types of data and problem scenarios. The choice between them can depend on factors like dataset size, the proportion of categorical features, need for model interpretability, and computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f9d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5498874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afa3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25eaafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bdf47cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vintage</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependents</th>\n",
       "      <th>current_balance</th>\n",
       "      <th>previous_month_end_balance</th>\n",
       "      <th>average_monthly_balance_prevQ</th>\n",
       "      <th>average_monthly_balance_prevQ2</th>\n",
       "      <th>current_month_credit</th>\n",
       "      <th>previous_month_credit</th>\n",
       "      <th>...</th>\n",
       "      <th>current_month_balance</th>\n",
       "      <th>previous_month_balance</th>\n",
       "      <th>occupation_company</th>\n",
       "      <th>occupation_retired</th>\n",
       "      <th>occupation_salaried</th>\n",
       "      <th>occupation_self_employed</th>\n",
       "      <th>occupation_student</th>\n",
       "      <th>customer_nw_category_1</th>\n",
       "      <th>customer_nw_category_2</th>\n",
       "      <th>customer_nw_category_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>1449.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2648</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5390.37</td>\n",
       "      <td>8704.66</td>\n",
       "      <td>7799.26</td>\n",
       "      <td>12419.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>6496.78</td>\n",
       "      <td>8787.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2494</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3913.16</td>\n",
       "      <td>5815.29</td>\n",
       "      <td>4910.17</td>\n",
       "      <td>2815.94</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>5006.28</td>\n",
       "      <td>5070.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2629</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2291.91</td>\n",
       "      <td>2291.91</td>\n",
       "      <td>2084.54</td>\n",
       "      <td>1006.54</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>2291.91</td>\n",
       "      <td>1669.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1879</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>927.72</td>\n",
       "      <td>1401.72</td>\n",
       "      <td>1643.31</td>\n",
       "      <td>1871.12</td>\n",
       "      <td>0.33</td>\n",
       "      <td>714.61</td>\n",
       "      <td>...</td>\n",
       "      <td>1157.15</td>\n",
       "      <td>1677.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vintage  age gender  dependents  current_balance  \\\n",
       "0     2401   66      0           0          1458.71   \n",
       "1     2648   35      0           0          5390.37   \n",
       "2     2494   31      0           0          3913.16   \n",
       "3     2629   90      0           1          2291.91   \n",
       "4     1879   42      0           2           927.72   \n",
       "\n",
       "   previous_month_end_balance  average_monthly_balance_prevQ  \\\n",
       "0                     1458.71                        1458.71   \n",
       "1                     8704.66                        7799.26   \n",
       "2                     5815.29                        4910.17   \n",
       "3                     2291.91                        2084.54   \n",
       "4                     1401.72                        1643.31   \n",
       "\n",
       "   average_monthly_balance_prevQ2  current_month_credit  \\\n",
       "0                         1449.07                  0.20   \n",
       "1                        12419.41                  0.56   \n",
       "2                         2815.94                  0.61   \n",
       "3                         1006.54                  0.47   \n",
       "4                         1871.12                  0.33   \n",
       "\n",
       "   previous_month_credit  ...  current_month_balance  previous_month_balance  \\\n",
       "0                   0.20  ...                1458.71                 1458.71   \n",
       "1                   0.56  ...                6496.78                 8787.61   \n",
       "2                   0.61  ...                5006.28                 5070.14   \n",
       "3                   0.47  ...                2291.91                 1669.79   \n",
       "4                 714.61  ...                1157.15                 1677.16   \n",
       "\n",
       "   occupation_company  occupation_retired  occupation_salaried  \\\n",
       "0                   0                   0                    0   \n",
       "1                   0                   0                    0   \n",
       "2                   0                   0                    1   \n",
       "3                   0                   0                    0   \n",
       "4                   0                   0                    0   \n",
       "\n",
       "   occupation_self_employed  occupation_student  customer_nw_category_1  \\\n",
       "0                         1                   0                       0   \n",
       "1                         1                   0                       0   \n",
       "2                         0                   0                       0   \n",
       "3                         1                   0                       0   \n",
       "4                         1                   0                       0   \n",
       "\n",
       "   customer_nw_category_2  customer_nw_category_3  \n",
       "0                       1                       0  \n",
       "1                       1                       0  \n",
       "2                       1                       0  \n",
       "3                       1                       0  \n",
       "4                       0                       1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"cleaned_churn_dataset.pkl\")\n",
    "X = df.drop('churn', axis=1)  # Features matrix\n",
    "y = df['churn']   # Target variable for Regression\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff8b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd8acbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(solver=\"liblinear\")  # \"untrained\" model\n",
    "LR.fit(X_train, y_train)  # model is trained now  >>> fitting means model training here.\n",
    "# Always fit your model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed688a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8230401004473044"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X_train, y_train)   # R^2 score of the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28300d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195229127432517"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X_test, y_test)   # R^2 score of the model on the TEST set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1ccb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "850065c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the display option\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22a8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d14b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195229127432517"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LR.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb2f947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2565,    8],\n",
       "       [ 567,   46]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c4d5f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90      2573\n",
      "         1.0       0.85      0.08      0.14       613\n",
      "\n",
      "    accuracy                           0.82      3186\n",
      "   macro avg       0.84      0.54      0.52      3186\n",
      "weighted avg       0.83      0.82      0.75      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred) ) #  target_names=[\"No Churn\", \"Churn\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33df14ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13793103448275862"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821a03f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0   0.81\n",
       "1.0   0.19\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6423b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b6b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c5f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion='gini', \n",
    "                                    max_depth=3, \n",
    "                                    random_state=1)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2486c76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(tree_model)\n",
    "#plt.savefig('images/03_21_1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfee5acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydotplus import graph_from_dot_data\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(tree_model,\n",
    "                           filled=True, \n",
    "                           rounded=True,\n",
    "                           class_names=['No Churn', \n",
    "                                        'Churn'],\n",
    "                           feature_names=list(X_train.columns),\n",
    "                           out_file=None) \n",
    "graph = graph_from_dot_data(dot_data) \n",
    "graph.write_png('tree.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7485ea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12743 entries, 6682 to 7270\n",
      "Data columns (total 22 columns):\n",
      " #   Column                          Non-Null Count  Dtype   \n",
      "---  ------                          --------------  -----   \n",
      " 0   vintage                         12743 non-null  int64   \n",
      " 1   age                             12743 non-null  int64   \n",
      " 2   gender                          12743 non-null  category\n",
      " 3   dependents                      12743 non-null  int64   \n",
      " 4   current_balance                 12743 non-null  float64 \n",
      " 5   previous_month_end_balance      12743 non-null  float64 \n",
      " 6   average_monthly_balance_prevQ   12743 non-null  float64 \n",
      " 7   average_monthly_balance_prevQ2  12743 non-null  float64 \n",
      " 8   current_month_credit            12743 non-null  float64 \n",
      " 9   previous_month_credit           12743 non-null  float64 \n",
      " 10  current_month_debit             12743 non-null  float64 \n",
      " 11  previous_month_debit            12743 non-null  float64 \n",
      " 12  current_month_balance           12743 non-null  float64 \n",
      " 13  previous_month_balance          12743 non-null  float64 \n",
      " 14  occupation_company              12743 non-null  uint8   \n",
      " 15  occupation_retired              12743 non-null  uint8   \n",
      " 16  occupation_salaried             12743 non-null  uint8   \n",
      " 17  occupation_self_employed        12743 non-null  uint8   \n",
      " 18  occupation_student              12743 non-null  uint8   \n",
      " 19  customer_nw_category_1          12743 non-null  uint8   \n",
      " 20  customer_nw_category_2          12743 non-null  uint8   \n",
      " 21  customer_nw_category_3          12743 non-null  uint8   \n",
      "dtypes: category(1), float64(10), int64(3), uint8(8)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "768dd203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8716258631512869\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, enable_categorical=True)\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "xgb_predictions = xgb_clf.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a57808d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5864509605662286"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, xgb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98fb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4927f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4cae2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2374, number of negative: 10369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2921\n",
      "[LightGBM] [Info] Number of data points in the train set: 12743, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.186298 -> initscore=-1.474244\n",
      "[LightGBM] [Info] Start training from score -1.474244\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Accuracy: 0.8697426239799121\n"
     ]
    }
   ],
   "source": [
    "# Initialize LightGBM classifier\n",
    "lgb_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=4)\n",
    "\n",
    "# Train the model\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "lgb_predictions = lgb_clf.predict(X_test)\n",
    "print(\"LightGBM Accuracy:\", accuracy_score(y_test, lgb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5318142e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5895153313550939"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lgb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9635ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e6e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a7dd276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Accuracy: 0.8688010043942247\n"
     ]
    }
   ],
   "source": [
    "# Initialize CatBoost classifier\n",
    "cb_clf = cb.CatBoostClassifier(n_estimators=100, learning_rate=0.1, depth=4, cat_features=[\"gender\"], verbose=0)\n",
    "\n",
    "# Train the model\n",
    "cb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "cb_predictions = cb_clf.predict(X_test)\n",
    "print(\"CatBoost Accuracy:\", accuracy_score(y_test, cb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8388b476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5895153313550939"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lgb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4375965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2aa45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fa9beb3",
   "metadata": {},
   "source": [
    "# Imp. Hyperparameters for XGBoost, LightGBM, and CatBoost:\n",
    "\n",
    "\n",
    "| Hyperparameter               | XGBoost                            | LightGBM                           | CatBoost                           |\n",
    "|------------------------------|------------------------------------|------------------------------------|------------------------------------|\n",
    "| **Learning Rate**            | `eta`                              | `learning_rate`                    | `learning_rate`                    |\n",
    "| **Number of Trees**          | `n_estimators`                     | `num_iterations` or `n_estimators` | `iterations`                       |\n",
    "| **Maximum Tree Depth**       | `max_depth`                        | `max_depth`                        | `depth`                            |\n",
    "| **Minimum Child Weight**     | `min_child_weight`                 | `min_data_in_leaf` or `min_child_samples` | `min_data_in_leaf`              |\n",
    "| **Subsample**                | `subsample`                        | `bagging_fraction`                 | `subsample` or `bagging_fraction`  |\n",
    "| **Colsample by Tree**        | `colsample_bytree`                 | `feature_fraction`                 | -                                  |\n",
    "| **Regularization (L1 / L2)** | `reg_alpha` / `reg_lambda`         | `lambda_l1` / `lambda_l2`          | `l2_leaf_reg` (only L2)            |\n",
    "| **Tree Method**              | `tree_method` (various options)    | -                                  | `boosting_type`                    |\n",
    "| **Histogram Binning**        | `max_bin` (for `hist` tree method) | `max_bin`                          | -                                  |\n",
    "| **Leaf-wise Growth**         | -                                  | `leaf_growth` (enabled by default) | -                                  |\n",
    "| **Handling Categorical Features** | Requires pre-processing        | Requires pre-processing            | Directly handles with `cat_features` |\n",
    "| **Early Stopping**           | Supported with `early_stopping_rounds` | Supported with `early_stopping_round` | Supported with `od_wait`         |\n",
    "| **Boosting Type**            | -                                  | `boosting_type` (default is `gbdt`) | `boosting_type` (various options)  |\n",
    "| **Specialized Regularization** | -                                | -                                  | `model_shrink_rate`                |\n",
    "\n",
    "These hyperparameters are the most commonly tuned ones and have a significant impact on the model's performance, generalization, and speed of training. While some hyperparameters are common across all three frameworks, each framework has its unique parameters, reflecting its underlying algorithmic differences. For instance, CatBoost's specialized handling of categorical features and LightGBM's focus on speed and efficiency with large datasets are reflected in their specific hyperparameters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe85861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088db97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "806fc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=n_splits,shuffle=True, random_state=101)  # >> shuffler & spliiter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c919c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] \n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, enable_categorical=True)\n",
    "models.append(('XGBoost', xgb_clf))\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=4)\n",
    "models.append(('LightGBM', lgb_clf))\n",
    "\n",
    "cb_clf = cb.CatBoostClassifier(n_estimators=100, learning_rate=0.1, depth=4, cat_features=[\"gender\"], verbose=0)\n",
    "models.append(('CatBoost', cb_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97b96081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost .... done!\n",
      "[LightGBM] [Info] Number of positive: 2390, number of negative: 10353\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2921\n",
      "[LightGBM] [Info] Number of data points in the train set: 12743, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187554 -> initscore=-1.465983\n",
      "[LightGBM] [Info] Start training from score -1.465983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 2390, number of negative: 10353\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2921\n",
      "[LightGBM] [Info] Number of data points in the train set: 12743, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187554 -> initscore=-1.465983\n",
      "[LightGBM] [Info] Start training from score -1.465983\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2389, number of negative: 10354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2923\n",
      "[LightGBM] [Info] Number of data points in the train set: 12743, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187475 -> initscore=-1.466498\n",
      "[LightGBM] [Info] Start training from score -1.466498\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 2389, number of negative: 10354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2922\n",
      "[LightGBM] [Info] Number of data points in the train set: 12743, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187475 -> initscore=-1.466498\n",
      "[LightGBM] [Info] Start training from score -1.466498\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 2390, number of negative: 10354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2921\n",
      "[LightGBM] [Info] Number of data points in the train set: 12744, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187539 -> initscore=-1.466080\n",
      "[LightGBM] [Info] Start training from score -1.466080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM .... done!\n",
      "CatBoost .... done!\n"
     ]
    }
   ],
   "source": [
    "cv_results = []\n",
    "n_splits = 5\n",
    "mean_train_score = []\n",
    "test_scores = []\n",
    "names = []\n",
    "\n",
    "# going to cross-validate all the 5 models\n",
    "for name, model in models:\n",
    "    results = cross_validate(model, X, y, return_train_score=True, cv=kfold, scoring=\"f1\")  # 'accuracy'\n",
    "    cv_results.append(results)\n",
    "    test_scores.append(results['test_score'] ) \n",
    "    mean_train_score.append(results['train_score'].mean().round(3) )\n",
    "    names.append(name)\n",
    "    print(name, \".... done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc4680dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV1</th>\n",
       "      <th>CV2</th>\n",
       "      <th>CV3</th>\n",
       "      <th>CV4</th>\n",
       "      <th>CV5</th>\n",
       "      <th>CV Mean</th>\n",
       "      <th>CV Std Dev</th>\n",
       "      <th>Mean_Train_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>58.04</td>\n",
       "      <td>57.40</td>\n",
       "      <td>56.03</td>\n",
       "      <td>55.57</td>\n",
       "      <td>52.99</td>\n",
       "      <td>56.01</td>\n",
       "      <td>1.96</td>\n",
       "      <td>63.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>58.39</td>\n",
       "      <td>55.34</td>\n",
       "      <td>55.16</td>\n",
       "      <td>56.22</td>\n",
       "      <td>51.73</td>\n",
       "      <td>55.37</td>\n",
       "      <td>2.40</td>\n",
       "      <td>58.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>57.38</td>\n",
       "      <td>56.22</td>\n",
       "      <td>54.90</td>\n",
       "      <td>55.21</td>\n",
       "      <td>51.58</td>\n",
       "      <td>55.06</td>\n",
       "      <td>2.17</td>\n",
       "      <td>59.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CV1   CV2   CV3   CV4   CV5  CV Mean  CV Std Dev  Mean_Train_Score\n",
       "LightGBM 58.04 57.40 56.03 55.57 52.99    56.01        1.96             63.80\n",
       "CatBoost 58.39 55.34 55.16 56.22 51.73    55.37        2.40             58.20\n",
       "XGBoost  57.38 56.22 54.90 55.21 51.58    55.06        2.17             59.70"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(test_scores, index=names, columns='CV1 CV2 CV3 CV4 CV5'.split() )\n",
    "results_df['CV Mean'] = np.round(results_df.iloc[:,0:n_splits].mean(axis=1), 4)\n",
    "results_df['CV Std Dev'] = np.round(results_df.iloc[:,0:n_splits].std(axis=1), 4)\n",
    "\n",
    "results_df['Mean_Train_Score'] = mean_train_score\n",
    "\n",
    "results_df.sort_values(by='CV Mean', ascending=False)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2808f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2435112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0639705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperPArameter Tuning using GridSearchÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bd7f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS FOR HP Tuning:\n",
    "#     1. Identify and narrow down the transformer/scaler/algo which we want to tune..\n",
    "#     2. Identify the Hyper param for that transformer/scaler/algo which we want to tune..\n",
    "#     3. Create a list/array of parameter values you want to search/try-out\n",
    "#     4. Create a dict of param_values you want to tune\n",
    "#     5. PAss the dict to GridSearchCV function, alongwith the model (step1) & CV object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae4e7f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.563302 using {'n_estimators': 200}\n",
      "0.550578 (0.019435) with: {'n_estimators': 100}\n",
      "0.561014 (0.017990) with: {'n_estimators': 150}\n",
      "0.563302 (0.019223) with: {'n_estimators': 200}\n",
      "0.563237 (0.020858) with: {'n_estimators': 250}\n",
      "0.561677 (0.019407) with: {'n_estimators': 300}\n",
      "0.560963 (0.017573) with: {'n_estimators': 350}\n",
      "0.557257 (0.019795) with: {'n_estimators': 400}\n",
      "0.556871 (0.020822) with: {'n_estimators': 450}\n",
      "0.556372 (0.021462) with: {'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# hYPRER paRAM tuning the pipiline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = np.arange(100, 550, 50)\n",
    "param_grid = {'n_estimators': n_estimators}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(learning_rate=0.1, max_depth=3, enable_categorical=True)\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='f1', cv=kfold, return_train_score=True)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3a2a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 200}, 0.5633024545653494)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_, grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7991695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.330245456534946"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_['mean_test_score'][grid_result.best_index_]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ccf7aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9222760414535511"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_['std_test_score'][grid_result.best_index_]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "047ba9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.97331112533408"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_['mean_train_score'][grid_result.best_index_]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be744271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55057755, 0.56101386, 0.56330245, 0.56323703, 0.56167726,\n",
       "       0.56096342, 0.55725732, 0.55687075, 0.5563721 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b917219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10ee5a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.2032557 , 0.27785711, 0.35725274, 0.44302101, 0.45219216,\n",
       "        0.48390017, 0.53855205, 0.62154322, 0.67100487]),\n",
       " 'std_fit_time': array([0.03094365, 0.02453212, 0.0575351 , 0.100181  , 0.03065342,\n",
       "        0.02140246, 0.03343732, 0.02492184, 0.03118629]),\n",
       " 'mean_score_time': array([0.01377053, 0.02234011, 0.01755209, 0.01714869, 0.01634989,\n",
       "        0.02235284, 0.02095046, 0.02053928, 0.01855154]),\n",
       " 'std_score_time': array([0.00271518, 0.00686915, 0.00583507, 0.0051424 , 0.00247928,\n",
       "        0.00287169, 0.00245324, 0.00325548, 0.00240996]),\n",
       " 'param_n_estimators': masked_array(data=[100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 100},\n",
       "  {'n_estimators': 150},\n",
       "  {'n_estimators': 200},\n",
       "  {'n_estimators': 250},\n",
       "  {'n_estimators': 300},\n",
       "  {'n_estimators': 350},\n",
       "  {'n_estimators': 400},\n",
       "  {'n_estimators': 450},\n",
       "  {'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.57378741, 0.58680203, 0.58787879, 0.59013092, 0.58669355,\n",
       "        0.58526741, 0.58156028, 0.58693467, 0.58634538]),\n",
       " 'split1_test_score': array([0.56218402, 0.56827309, 0.57596822, 0.57874016, 0.57677165,\n",
       "        0.57423795, 0.57226562, 0.57198444, 0.5750242 ]),\n",
       " 'split2_test_score': array([0.54897959, 0.55846774, 0.56193353, 0.55477387, 0.55533199,\n",
       "        0.55790534, 0.55790534, 0.55533199, 0.55186304]),\n",
       " 'split3_test_score': array([0.55214724, 0.56040609, 0.56016178, 0.56306761, 0.55927052,\n",
       "        0.55297679, 0.55040323, 0.54141414, 0.53993933]),\n",
       " 'split4_test_score': array([0.51578947, 0.53112033, 0.53056995, 0.5294726 , 0.5303186 ,\n",
       "        0.5344296 , 0.52415211, 0.52868852, 0.52868852]),\n",
       " 'mean_test_score': array([0.55057755, 0.56101386, 0.56330245, 0.56323703, 0.56167726,\n",
       "        0.56096342, 0.55725732, 0.55687075, 0.5563721 ]),\n",
       " 'std_test_score': array([0.0194352 , 0.01799   , 0.01922276, 0.02085818, 0.01940657,\n",
       "        0.01757315, 0.01979514, 0.02082199, 0.02146181]),\n",
       " 'rank_test_score': array([9, 4, 1, 2, 3, 5, 6, 7, 8]),\n",
       " 'split0_train_score': array([0.5958536 , 0.61476033, 0.62673043, 0.64251811, 0.65472637,\n",
       "        0.66418096, 0.67130089, 0.68281829, 0.69380706]),\n",
       " 'split1_train_score': array([0.59928168, 0.62278481, 0.63526448, 0.64783804, 0.66117764,\n",
       "        0.66949364, 0.67993037, 0.68946716, 0.69573835]),\n",
       " 'split2_train_score': array([0.59790656, 0.61304238, 0.62841254, 0.64391468, 0.65403789,\n",
       "        0.66749627, 0.67612646, 0.68722029, 0.69414101]),\n",
       " 'split3_train_score': array([0.59133999, 0.61128049, 0.6254417 , 0.63796576, 0.6497996 ,\n",
       "        0.66084788, 0.66865672, 0.67759563, 0.68666336]),\n",
       " 'split4_train_score': array([0.6011236 , 0.61759516, 0.63281641, 0.64321357, 0.65272591,\n",
       "        0.66534457, 0.6767103 , 0.68541821, 0.69471095]),\n",
       " 'mean_train_score': array([0.59710109, 0.61589263, 0.62973311, 0.64309003, 0.65449348,\n",
       "        0.66547266, 0.67454495, 0.68450392, 0.69301215]),\n",
       " 'std_train_score': array([0.00335651, 0.00402688, 0.00372234, 0.00315671, 0.00374424,\n",
       "        0.00294404, 0.00403455, 0.00408446, 0.00324134])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f5277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0eb5bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4fe8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb38b133",
   "metadata": {},
   "source": [
    "# FInal Model Trianing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f82462e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b3332c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_ensemble_model.pkl', 'wb') as handle:\n",
    "    pickle.dump(final_model, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520b58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55a9d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32d19da6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal_model\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "caceaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pickle.load(open('final_ensemble_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f35dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
